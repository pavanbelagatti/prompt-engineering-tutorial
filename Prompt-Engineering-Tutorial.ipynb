{"cells":[{"cell_type":"markdown","id":"dcaebbd4-f931-4a4f-951d-f0ce6a89bc55","metadata":{"language":"python"},"source":"## We need OpenAI and LangChain, so install them."},{"cell_type":"code","execution_count":168,"id":"281b53bf-c3c7-4f4e-b253-965fc8a88a61","metadata":{"execution":{"iopub.execute_input":"2024-01-04T06:14:42.644101Z","iopub.status.busy":"2024-01-04T06:14:42.643838Z","iopub.status.idle":"2024-01-04T06:14:46.380614Z","shell.execute_reply":"2024-01-04T06:14:46.380023Z","shell.execute_reply.started":"2024-01-04T06:14:42.644080Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: openai in /opt/conda/lib/python3.11/site-packages (1.6.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (4.0.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.26.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from openai) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from openai) (4.8.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\nRequirement already satisfied: langchain in /opt/conda/lib/python3.11/site-packages (0.0.354)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.0.21)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.11/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.6.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain) (1.33)\nRequirement already satisfied: langchain-community<0.1,>=0.0.8 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.0.8)\nRequirement already satisfied: langchain-core<0.2,>=0.1.5 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.1.5)\nRequirement already satisfied: langsmith<0.1.0,>=0.0.77 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.0.77)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain) (1.26.2)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.5->langchain) (4.0.0)\nRequirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.5->langchain) (23.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.5->langchain) (1.3.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"}],"source":"!pip install openai\n!pip install langchain"},{"cell_type":"markdown","id":"1fd92cae-a28a-4824-8ec3-2160879291f0","metadata":{"language":"python"},"source":"## Add OpenAI API Key"},{"cell_type":"code","execution_count":21,"id":"d7011154-7699-448d-8cdc-24145a9f75a2","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:32:11.467130Z","iopub.status.busy":"2024-01-04T05:32:11.466860Z","iopub.status.idle":"2024-01-04T05:32:11.469850Z","shell.execute_reply":"2024-01-04T05:32:11.469247Z","shell.execute_reply.started":"2024-01-04T05:32:11.467114Z"},"language":"python","trusted":true},"outputs":[],"source":"import os\nos.environ[\"OPENAI_API_KEY\"] = \"\""},{"cell_type":"markdown","id":"b533e4f3-3740-456a-a4a0-1cb583620e46","metadata":{"language":"python"},"source":"## Design a simple PromptTemplate"},{"cell_type":"code","execution_count":46,"id":"ea841be3-f937-47ae-97d2-479f87e5b3c7","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:38:43.483991Z","iopub.status.busy":"2024-01-04T05:38:43.483746Z","iopub.status.idle":"2024-01-04T05:38:43.590738Z","shell.execute_reply":"2024-01-04T05:38:43.590183Z","shell.execute_reply.started":"2024-01-04T05:38:43.483976Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"'I want you to act as a Generative AI expert for people.\\nIn an easy way, explain the basics of large language models.'"},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":"from langchain import PromptTemplate\n\ndemo_template='''I want you to act as a Generative AI expert for people.\nIn an easy way, explain the basics of {genai_concept}.'''\n\nprompt=PromptTemplate(\n    input_variables=['genai_concept'],\n    template=demo_template\n    )\n\nprompt.format(genai_concept='large language models')"},{"cell_type":"markdown","id":"ae179b23-e547-4a43-8225-3c73dbd03e9b","metadata":{"language":"python"},"source":"## Set up the environment \n\nSetting up an environment using the LangChain library to interact with an OpenAI language model. It configures the model with a specific temperature and prepares an LLMChain to execute a sequence of operations with the model."},{"cell_type":"code","execution_count":58,"id":"cfe37201-1bcf-451c-958e-6f508f856f51","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:41:00.312832Z","iopub.status.busy":"2024-01-04T05:41:00.312585Z","iopub.status.idle":"2024-01-04T05:41:00.532368Z","shell.execute_reply":"2024-01-04T05:41:00.531867Z","shell.execute_reply.started":"2024-01-04T05:41:00.312816Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain.llms import OpenAI\nfrom langchain.chains import LLMChain\n\nllm=OpenAI(temperature=0.7)\nchain1=LLMChain(llm=llm,prompt=prompt)"},{"cell_type":"markdown","id":"bb96fe3e-8d0e-46ec-bddc-06a22925095a","metadata":{"language":"python"},"source":"## Run the LLMChain with our zero-shot prompt input"},{"cell_type":"code","execution_count":60,"id":"bf840de0-494b-4f7d-bf6e-b97f43639cf4","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:41:23.132063Z","iopub.status.busy":"2024-01-04T05:41:23.131798Z","iopub.status.idle":"2024-01-04T05:41:26.241375Z","shell.execute_reply":"2024-01-04T05:41:26.240781Z","shell.execute_reply.started":"2024-01-04T05:41:23.132047Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"'\\n\\nLarge language models are a type of artificial intelligence that is trained on a large amount of text data in order to generate human-like language. They use complex algorithms and deep learning techniques to understand the patterns and structure of language, allowing them to produce sentences and paragraphs that are grammatically correct and coherent.\\n\\nThese models are able to learn from a vast amount of data, such as books, articles, and websites, and then use that knowledge to generate new text. They are particularly good at understanding context and can generate responses that are relevant to a given topic or prompt.\\n\\nOne of the most notable large language models is known as GPT-3 (Generative Pre-trained Transformer 3), which has been trained on over 175 billion parameters. This means it has a vast amount of knowledge and can generate text that is almost indistinguishable from human-written text.\\n\\nLarge language models have many potential applications, such as creating content for websites, chatbots, and virtual assistants, as well as aiding in language translation and summarization. However, there are also concerns about their potential misuse, such as generating fake news or biased content.\\n\\nIn summary, large language models are powerful AI systems that can generate human-like language by learning from a large amount of text data. They have a wide range'"},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":"chain1.run('large language models')"},{"cell_type":"markdown","id":"1641a12a-d278-4a59-9698-3bbca8b6ae14","metadata":{"language":"python"},"source":"## Simple language translation Template"},{"cell_type":"code","execution_count":75,"id":"38dc5ae7-8feb-40a5-84e1-1f59a82af3ad","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:45:31.555379Z","iopub.status.busy":"2024-01-04T05:45:31.555099Z","iopub.status.idle":"2024-01-04T05:45:31.559885Z","shell.execute_reply":"2024-01-04T05:45:31.559290Z","shell.execute_reply.started":"2024-01-04T05:45:31.555364Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"\"In an easy way translate the following sentence 'What is your name' into German\""},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":"from langchain import PromptTemplate\n\ntemplate='''In an easy way translate the following sentence '{sentence}' into {target_language}'''\nlanguage_prompt = PromptTemplate(\n    input_variables=[\"sentence\",'target_language'],\n    template=template,\n)\nlanguage_prompt.format(sentence=\"What is your name\",target_language='German')"},{"cell_type":"markdown","id":"4b027382-75fe-4e6e-b4e0-e86313b58833","metadata":{"language":"python"},"source":"## Create the LLMChain to execute our requirement"},{"cell_type":"code","execution_count":78,"id":"7e832875-9b7b-47e8-8cfb-15430c53bf7b","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:46:13.556930Z","iopub.status.busy":"2024-01-04T05:46:13.556627Z","iopub.status.idle":"2024-01-04T05:46:13.954268Z","shell.execute_reply":"2024-01-04T05:46:13.953657Z","shell.execute_reply.started":"2024-01-04T05:46:13.556914Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"{'sentence': 'Hello, what is your name',\n 'target_language': 'German',\n 'text': '\\n\\nHallo, wie ist dein Name?'}"},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":"chain2=LLMChain(llm=llm,prompt=language_prompt)\n\nchain2({'sentence':\"Hello, what is your name\",'target_language':'German'})"},{"cell_type":"markdown","id":"194ca348-e6a6-4150-bd65-e87d0947b899","metadata":{"language":"python"},"source":"## Few-Shot Prompt Template"},{"cell_type":"code","execution_count":105,"id":"e007ff9b-f01a-40f8-b78b-4ecfca514d89","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:56:58.231464Z","iopub.status.busy":"2024-01-04T05:56:58.231215Z","iopub.status.idle":"2024-01-04T05:56:58.235026Z","shell.execute_reply":"2024-01-04T05:56:58.234475Z","shell.execute_reply.started":"2024-01-04T05:56:58.231448Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain import PromptTemplate, FewShotPromptTemplate\n\n# First, create the list of few shot examples.\nexamples = [\n    {\"word\": \"fast\", \"synonym\": \"quick\"},\n    {\"word\": \"hard\", \"synonym\": \"difficult\"},\n]\n\n# Next, we specify the template to format the examples we have provided.\n# We use the `PromptTemplate` class for this.\nexample_formatter_template = \"\"\"Word: {word}\nSynonym: {synonym}\n\"\"\"\n\nexample_prompt = PromptTemplate(\n    input_variables=[\"word\", \"synonym\"],\n    template=example_formatter_template,\n)"},{"cell_type":"code","execution_count":111,"id":"84be84d4-eb59-4271-aa29-1e3fb2e0ec73","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:58:19.034336Z","iopub.status.busy":"2024-01-04T05:58:19.033855Z","iopub.status.idle":"2024-01-04T05:58:19.037503Z","shell.execute_reply":"2024-01-04T05:58:19.036955Z","shell.execute_reply.started":"2024-01-04T05:58:19.034314Z"},"language":"python","trusted":true},"outputs":[],"source":"# Finally, we create the `FewShotPromptTemplate` object.\nfew_shot_prompt = FewShotPromptTemplate(\n    # These are the examples we want to insert into the prompt.\n    examples=examples,\n    # This is how we want to format the examples when we insert them into the prompt.\n    example_prompt=example_prompt,\n    # The prefix is some text that goes before the examples in the prompt.\n    # Usually, this consists of intructions.\n    prefix=\"Give the synonym of every input\\n\",\n    # The suffix is some text that goes after the examples in the prompt.\n    # Usually, this is where the user input will go\n    suffix=\"Word: {input}\\nSynonym: \",\n    # The input variables are the variables that the overall prompt expects.\n    input_variables=[\"input\"],\n    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n    example_separator=\"\\n\",\n)"},{"cell_type":"code","execution_count":112,"id":"ef53ae31-3017-4ae1-ab06-27c428faab55","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:58:38.787838Z","iopub.status.busy":"2024-01-04T05:58:38.787476Z","iopub.status.idle":"2024-01-04T05:58:38.791142Z","shell.execute_reply":"2024-01-04T05:58:38.790557Z","shell.execute_reply.started":"2024-01-04T05:58:38.787819Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Give the synonym of every input\n\nWord: fast\nSynonym: quick\n\nWord: hard\nSynonym: difficult\n\nWord: Elegant\nSynonym: \n"}],"source":"print(few_shot_prompt.format(input='Elegant'))"},{"cell_type":"markdown","id":"c609a325-275b-425d-a8bf-0967f6e17600","metadata":{"language":"python"},"source":"## Create the chain and run"},{"cell_type":"code","execution_count":115,"id":"15bc4854-63d8-462a-b901-a08ca3528dd6","metadata":{"execution":{"iopub.execute_input":"2024-01-04T05:59:03.165113Z","iopub.status.busy":"2024-01-04T05:59:03.164840Z","iopub.status.idle":"2024-01-04T05:59:03.485391Z","shell.execute_reply":"2024-01-04T05:59:03.484823Z","shell.execute_reply.started":"2024-01-04T05:59:03.165098Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"{'input': 'Elegant', 'text': 'stylish'}"},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":"chain=LLMChain(llm=llm,prompt=few_shot_prompt)\nchain({'input':\"Elegant\"})"}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"ef511a14-4713-491d-890d-f7aff864ff0a","defaultDatabase":""}},"nbformat":4,"nbformat_minor":5}